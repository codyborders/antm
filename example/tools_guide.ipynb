{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Start Example (Optional)\n",
        "\n",
        "This notebook demonstrates basic data access patterns using DuckDB and pandas. For a deeper dive into building full analytics agents on MotherDuck (prompt design, MCP integration, security), see [MotherDuck’s analytics agent guide](https://motherduck.com/docs/key-tasks/ai-and-motherduck/building-analytics-agents/).\n",
        "\n",
        "## Contents\n",
        "- Tool installation\n",
        "- Loading Parquet files\n",
        "- SQL queries\n",
        "- Log file parsing\n",
        "- Submission format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Tools\n",
        "\n",
        "Run this once:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "# %pip install -q duckdb pandas pyarrow lancedb\n",
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to DuckDB\n",
        "\n",
        "DuckDB lets you run SQL queries on Parquet files. It's fast and works well for analytics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to DuckDB\n"
          ]
        }
      ],
      "source": [
        "con = duckdb.connect('retail.duckdb')\n",
        "print(\"Connected to DuckDB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 1: Load Data into local DuckDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Parquet files into DuckDB so you can query them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Created 16 tables\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('catalog_sales',),\n",
              " ('customer',),\n",
              " ('customer_address',),\n",
              " ('customer_demographics',),\n",
              " ('date_dim',),\n",
              " ('household_demographics',),\n",
              " ('income_band',),\n",
              " ('inventory',),\n",
              " ('item',),\n",
              " ('logs',),\n",
              " ('promotion',),\n",
              " ('reason',),\n",
              " ('store',),\n",
              " ('store_returns',),\n",
              " ('store_sales',),\n",
              " ('warehouse',),\n",
              " ('web_sales',)]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List all parquet files in our GCS bucket\n",
        "files = con.execute(\"SELECT file FROM glob('gs://antm-dataset/**/*.parquet')\").fetchall()\n",
        "\n",
        "# Create table for each file\n",
        "for file_path, in files:\n",
        "    table_name = Path(file_path).stem\n",
        "    con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM read_parquet('{file_path}')\")\n",
        "\n",
        "# Show tables\n",
        "print(f\"\\nCreated {len(files)} tables\")\n",
        "con.execute(\"SHOW TABLES\").fetchall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 2: Connect to MotherDuck\n",
        "\n",
        "MotherDuck gives your local DuckDB cloud compute resources. It also lets you share data with others easily. \n",
        "\n",
        "1. Go to [app.motherduck.com](https://app.motherduck.com) and create an account.\n",
        "2. [create an access token](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-motherduck/authenticating-to-motherduck/#creating-an-access-token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"motherduck_token\"] = \"your_actual_token_here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create [read-write clone](https://motherduck.com/docs/key-tasks/ai-and-motherduck/building-analytics-agents/#read-write-access--sandboxing) of 'antm_hack' MotherDuck Share."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.environ.get(\"motherduck_token\") == \"your_actual_token_here\":\n",
        "    print(\"Using local DuckDB\")\n",
        "else:\n",
        "    print(\"Creating 'antm_hack_rw' database, from 'antm_hack' share\")\n",
        "\n",
        "    con.execute(\"CREATE DATABASE antm_hack_rw FROM 'md:_share/antm_hack/88329567-1b97-4593-9696-73fd2be9c63d'\")\n",
        "    con.execute(\"USE antm_hack_rw\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run a Query\n",
        "\n",
        "Example: Find top customers by spending\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if customer_path.exists():\n",
        "    query = \"\"\"\n",
        "    SELECT \n",
        "        c_customer_sk,\n",
        "        c_first_name,\n",
        "        c_last_name\n",
        "    FROM customer\n",
        "    ORDER BY c_customer_sk\n",
        "    LIMIT 5\n",
        "    \"\"\"\n",
        "    \n",
        "    result = con.execute(query).df()\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Log Files\n",
        "\n",
        "Logs are in JSONL format (one JSON object per line). You can use pandas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "ex_path = Path('../dataset/data/logs/customer_service.jsonl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 9400 events\n",
            "  ticket_id                 timestamp        category  customer_sk  priority  \\\n",
            "0  CS-22048 2022-04-25 03:40:36+00:00  product_defect        30144    medium   \n",
            "1  CS-79521 2020-08-18 23:21:33+00:00  return_request        53158    medium   \n",
            "2  CS-70494 2019-09-10 08:57:17+00:00  product_defect        51657       low   \n",
            "3  CS-58144 2018-12-21 00:27:03+00:00    out_of_stock        80348  critical   \n",
            "4  CS-11925 2018-08-17 09:24:33+00:00  return_request        19650       low   \n",
            "\n",
            "   item_sk  warehouse_sk request_id request_source status assigned_to  \\\n",
            "0   2114.0           2.0        NaN            NaN    NaN         NaN   \n",
            "1   9741.0           4.0        NaN            NaN    NaN         NaN   \n",
            "2   1428.0           NaN        NaN            NaN    NaN         NaN   \n",
            "3   2067.0           3.0        NaN            NaN    NaN         NaN   \n",
            "4   2105.0           1.0        NaN            NaN    NaN         NaN   \n",
            "\n",
            "  requester_email notes completed_date  \n",
            "0             NaN   NaN            NaN  \n",
            "1             NaN   NaN            NaN  \n",
            "2             NaN   NaN            NaN  \n",
            "3             NaN   NaN            NaN  \n",
            "4             NaN   NaN            NaN  \n"
          ]
        }
      ],
      "source": [
        "if ex_path.exists():\n",
        "    logs = pd.read_json('../dataset/data/logs/customer_service.jsonl', lines=True)\n",
        "    print(f\"Loaded {len(logs)} events\")\n",
        "    print(logs.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Query Logs with DuckDB\n",
        "\n",
        "You can also load logs into DuckDB and use SQL:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          category  count\n",
            "0   shipping_delay   2715\n",
            "1     out_of_stock   2322\n",
            "2   product_defect   1894\n",
            "3   return_request   1382\n",
            "4  general_inquiry    887\n",
            "5             None    200\n"
          ]
        }
      ],
      "source": [
        "if ex_path.exists():\n",
        "    con.execute(\"CREATE OR REPLACE TABLE logs AS SELECT * FROM read_json_auto('../dataset/data/logs/customer_service.jsonl')\")\n",
        "    \n",
        "    result = con.execute(\"\"\"\n",
        "        SELECT category, COUNT(*) as count \n",
        "        FROM logs \n",
        "        GROUP BY category\n",
        "        ORDER BY count DESC\n",
        "        LIMIT 10\n",
        "    \"\"\").df()\n",
        "    \n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using LanceDB for Semantic Search\n",
        "\n",
        "LanceDB is useful when you need to search by meaning rather than exact matches. Example use case: searching through log descriptions or PDF content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 9400 rows into LanceDB\n",
            "\n",
            "Sample product view events:\n",
            "  ticket_id                 timestamp      category  customer_sk  priority  \\\n",
            "0  CS-58144 2018-12-21 00:27:03+00:00  out_of_stock        80348  critical   \n",
            "1  CS-33960 2020-07-02 13:26:06+00:00  out_of_stock        90539    medium   \n",
            "2  CS-95195 2020-04-06 06:10:54+00:00  out_of_stock       100395       low   \n",
            "3  CS-48994 2018-09-22 20:20:02+00:00  out_of_stock        28988    medium   \n",
            "4  CS-38729 2022-04-30 17:24:01+00:00  out_of_stock        31062    medium   \n",
            "\n",
            "   item_sk  warehouse_sk request_id request_source status assigned_to  \\\n",
            "0   2067.0           3.0       None           None   None        None   \n",
            "1   8784.0           2.0       None           None   None        None   \n",
            "2   1471.0           1.0       None           None   None        None   \n",
            "3   2115.0           2.0       None           None   None        None   \n",
            "4   1679.0           2.0       None           None   None        None   \n",
            "\n",
            "  requester_email notes completed_date  \n",
            "0            None  None           None  \n",
            "1            None  None           None  \n",
            "2            None  None           None  \n",
            "3            None  None           None  \n",
            "4            None  None           None  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "┌───────────┬──────────────────────────┬──────────────┬─────────────┬──────────┬─────────┬──────────────┬────────────┬────────────────┬────────┬─────────────┬─────────────────┬───────┬────────────────┐\n",
              "│ ticket_id │        timestamp         │   category   │ customer_sk │ priority │ item_sk │ warehouse_sk │ request_id │ request_source │ status │ assigned_to │ requester_email │ notes │ completed_date │\n",
              "│  varchar  │ timestamp with time zone │   varchar    │    int64    │ varchar  │ double  │    double    │   int32    │     int32      │ int32  │    int32    │      int32      │ int32 │     int32      │\n",
              "├───────────┼──────────────────────────┼──────────────┼─────────────┼──────────┼─────────┼──────────────┼────────────┼────────────────┼────────┼─────────────┼─────────────────┼───────┼────────────────┤\n",
              "│ CS-58144  │ 2018-12-20 16:27:03-08   │ out_of_stock │       80348 │ critical │  2067.0 │          3.0 │       NULL │           NULL │   NULL │        NULL │            NULL │  NULL │           NULL │\n",
              "│ CS-33960  │ 2020-07-02 06:26:06-07   │ out_of_stock │       90539 │ medium   │  8784.0 │          2.0 │       NULL │           NULL │   NULL │        NULL │            NULL │  NULL │           NULL │\n",
              "│ CS-95195  │ 2020-04-05 23:10:54-07   │ out_of_stock │      100395 │ low      │  1471.0 │          1.0 │       NULL │           NULL │   NULL │        NULL │            NULL │  NULL │           NULL │\n",
              "│ CS-48994  │ 2018-09-22 13:20:02-07   │ out_of_stock │       28988 │ medium   │  2115.0 │          2.0 │       NULL │           NULL │   NULL │        NULL │            NULL │  NULL │           NULL │\n",
              "│ CS-38729  │ 2022-04-30 10:24:01-07   │ out_of_stock │       31062 │ medium   │  1679.0 │          2.0 │       NULL │           NULL │   NULL │        NULL │            NULL │  NULL │           NULL │\n",
              "└───────────┴──────────────────────────┴──────────────┴─────────────┴──────────┴─────────┴──────────────┴────────────┴────────────────┴────────┴─────────────┴─────────────────┴───────┴────────────────┘"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import lancedb\n",
        "\n",
        "# Connect to LanceDB\n",
        "db = lancedb.connect('lance_db')\n",
        "\n",
        "# Example: Load log data into LanceDB\n",
        "if ex_path.exists():\n",
        "    log_data = pd.read_json(ex_path, lines=True)\n",
        "    \n",
        "    # Create a table\n",
        "    table = db.create_table(\"logs\", data=log_data, mode=\"overwrite\")\n",
        "    \n",
        "    print(f\"Loaded {len(log_data)} rows into LanceDB\")\n",
        "    \n",
        "    # Query example: Filter logs\n",
        "    results = table.search().where(\"category = 'out_of_stock'\").limit(5).to_pandas()\n",
        "    print(\"\\nSample product view events:\")\n",
        "    print(results)\n",
        "else:\n",
        "    print(\"Log files not found.\")\n",
        "\n",
        "\n",
        "## Query LanceDB table or pandas DataFrame with DuckDB\n",
        "arrow_table = table.to_lance()\n",
        "con.query(\"SELECT * FROM arrow_table\")\n",
        "con.query(\"SELECT * FROM results\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission Format\n",
        "\n",
        "Save your answers in CSV format:\n",
        "\n",
        "```csv\n",
        "question_id,answer_type,answer_value,confidence,explanation\n",
        "1,customer_id,12345,high,Top customer by revenue\n",
        "1,total_spent,50000,high,Sum of net_paid\n",
        "```\n",
        "\n",
        "Create submissions programmatically:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   question_id  answer_type  answer_value confidence              explanation\n",
            "0            1  customer_id         12345       high  Top customer by revenue\n",
            "1            1  total_spent         50000       high          Sum of net_paid\n"
          ]
        }
      ],
      "source": [
        "submission = pd.DataFrame([\n",
        "    {'question_id': 1, 'answer_type': 'customer_id', 'answer_value': 12345, 'confidence': 'high', 'explanation': 'Top customer by revenue'},\n",
        "    {'question_id': 1, 'answer_type': 'total_spent', 'answer_value': 50000, 'confidence': 'high', 'explanation': 'Sum of net_paid'},\n",
        "])\n",
        "\n",
        "print(submission)\n",
        "\n",
        "# To save:\n",
        "# submission.to_csv('my_submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Competition Structure\n",
        "\n",
        "**Training Round (12:30-2:00):** 25 questions with answers provided. Practice only, no submission required.\n",
        "\n",
        "**Test Round (2:00-6:00):** 30 questions without answers. Submit by 6:00 PM. Worth 70% of final score.\n",
        "\n",
        "**Holdout Round (6:00-7:30):** 20 secret questions. We run your system automatically. Worth 30% of final score.\n",
        "\n",
        "That's the basics. Check the README for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool Use Cases\n",
        "\n",
        "**DuckDB:** SQL queries on structured data (Parquet tables) and logs. Fast for aggregations, joins, filtering.\n",
        "\n",
        "**LanceDB:** Semantic search when you need to find things by meaning, not exact matches. Good for searching PDFs or finding similar log entries.\n",
        "\n",
        "**MotherDuck:** Cloud version of DuckDB. Useful for sharing data/queries with teammates or working with larger datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MCP Server Quickstart\n",
        "\n",
        "1. **Pick a language/runtime.** MCP servers only need stdin/stdout plus JSON-RPC. Python (`mcp`), TypeScript (`@modelcontextprotocol/server`), or Go all work.\n",
        "2. **Choose resources.** Decide what data you’ll expose (DuckDB tables, Parquet files, PDF search). Give each a stable URI so clients know how to reference them.\n",
        "3. **Implement tools.** Each MCP tool wraps an action—run SQL, summarize a log window, fetch a PDF section. Keep inputs/outputs typed and minimal so LLMs can call them safely.\n",
        "4. **Advertise capabilities.** In `initialize` return your tool/resource metadata so Cursor/Claude Desktop lists them automatically.\n",
        "5. **Run & register.** Start the server (e.g., `python mcp_server.py`) and add that command under `Cursor → Settings → MCP Servers`.\n",
        "\n",
        "### DuckDB FastMCP example\n",
        "\n",
        "Here's a minimal Python scaffolding for DuckDB:\n",
        "\n",
        "```python\n",
        "from fastmcp import FastMCP\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect('retail.duckdb')\n",
        "mcp = FastMCP()\n",
        "\n",
        "@mcp.tool(name=\"duckdb_describe_customer\")\n",
        "def describe_customer(limit: int = 5) -> list[dict[str, str]]:\n",
        "    \"\"\"Return sample customer rows from DuckDB.\"\"\"\n",
        "    rows = con.execute(\n",
        "        \"SELECT c_customer_sk, c_first_name, c_last_name FROM customer LIMIT ?\",\n",
        "        [limit],\n",
        "    ).fetchall()\n",
        "    return [dict(row) for row in rows]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mcp.run()\n",
        "```\n",
        "\n",
        "Register `python mcp_server.py` as a custom MCP server and the `describe_customer` tool becomes available directly in your prompts.\n",
        "\n",
        "> **Shortcut:** Don’t want to build your own? MotherDuck ships an OSS MCP server that connects to both DuckDB and MotherDuck backends, complete with SaaS/read-only modes and Claude/Cursor examples. Install it via `uvx mcp-server-motherduck …` using the instructions in their repo: https://github.com/motherduckdb/mcp-server-motherduck.\n",
        "\n",
        "### LanceDB FastMCP example\n",
        "\n",
        "LanceDB also provides an MCP server that exposes read and write tools. Here's a minimal example.\n",
        "\n",
        "```python\n",
        "from mcp.server.fastmcp import FastMCPServer\n",
        "import lancedb\n",
        "\n",
        "# Re-use the `lance_db` directory populated earlier\n",
        "# (or point to any LanceDB-backed dataset you want to expose)\n",
        "db = lancedb.connect(\"lance_db\")\n",
        "server = FastMCPServer()\n",
        "\n",
        "@mcp.tool(name=\"lancedb_search_logs\")\n",
        "def search_logs(query: str, limit: int = 5) -> list[dict]:\n",
        "    \"\"\"Return log rows semantically similar to the text query.\"\"\"\n",
        "    table = db.open_table(\"logs\")\n",
        "    matches = table.search(query).limit(limit).to_list()\n",
        "    return matches\n",
        "\n",
        "@server.tool(name=\"lancedb_list_tables\")\n",
        "def list_tables() -> list[str]:\n",
        "    \"\"\"List available LanceDB tables.\"\"\"\n",
        "    return db.table_names()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    server.run()\n",
        "```\n",
        "\n",
        "Register this script the same way as the DuckDB example and you now have semantic search tools on tap. Prefer a maintained implementation instead? The LanceDB team ships a ready-to-run FastMCP server (CLI plus config examples) here: https://github.com/lancedb/lancedb-mcp-server.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "antm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
