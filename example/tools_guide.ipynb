{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Start Example (Optional)\n",
        "\n",
        "This notebook demonstrates basic data access patterns using DuckDB and pandas.\n",
        "\n",
        "## Contents\n",
        "- Tool installation\n",
        "- Loading Parquet files\n",
        "- SQL queries\n",
        "- Log file parsing\n",
        "- Submission format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Tools\n",
        "\n",
        "Run this once:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the '/Users/panthbhavsar/Documents/theory/modeler-hackathon-starter/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q duckdb pandas pyarrow lancedb\n",
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to DuckDB\n",
        "\n",
        "DuckDB lets you run SQL queries on Parquet files. It's fast and works well for analytics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to DuckDB\n"
          ]
        }
      ],
      "source": [
        "con = duckdb.connect('retail.duckdb')\n",
        "print(\"Connected to DuckDB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "Load Parquet files into DuckDB so you can query them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data files not found. Download the dataset first.\n"
          ]
        }
      ],
      "source": [
        "# Load a few example tables\n",
        "# You'll need to load all 24 tables for the actual competition\n",
        "\n",
        "if Path('data/parquet/customer.parquet').exists():\n",
        "    con.execute(\"CREATE OR REPLACE TABLE customer AS SELECT * FROM 'data/parquet/customer.parquet'\")\n",
        "    con.execute(\"CREATE OR REPLACE TABLE store_sales AS SELECT * FROM 'data/parquet/store_sales.parquet'\")\n",
        "    con.execute(\"CREATE OR REPLACE TABLE date_dim AS SELECT * FROM 'data/parquet/date_dim.parquet'\")\n",
        "    \n",
        "    print(\"Tables loaded\")\n",
        "    print(con.execute(\"SHOW TABLES\").df())\n",
        "else:\n",
        "    print(\"Data files not found. Download the dataset first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run a Query\n",
        "\n",
        "Example: Find top customers by spending\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "if Path('data/parquet/customer.parquet').exists():\n",
        "    query = \"\"\"\n",
        "    SELECT \n",
        "        c.c_customer_sk,\n",
        "        c.c_first_name,\n",
        "        c.c_last_name,\n",
        "        SUM(ss.ss_net_paid) as total_spent\n",
        "    FROM store_sales ss\n",
        "    JOIN customer c ON ss.ss_customer_sk = c.c_customer_sk\n",
        "    JOIN date_dim d ON ss.ss_sold_date_sk = d.d_date_sk\n",
        "    WHERE d.d_year = 2023\n",
        "    GROUP BY c.c_customer_sk, c.c_first_name, c.c_last_name\n",
        "    ORDER BY total_spent DESC\n",
        "    LIMIT 5\n",
        "    \"\"\"\n",
        "    \n",
        "    result = con.execute(query).df()\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Log Files\n",
        "\n",
        "Logs are in JSONL format (one JSON object per line). You can use pandas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "if Path('data/logs/clickstream.jsonl').exists():\n",
        "    logs = pd.read_json('data/logs/clickstream.jsonl', lines=True)\n",
        "    print(f\"Loaded {len(logs)} events\")\n",
        "    print(logs.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Query Logs with DuckDB\n",
        "\n",
        "You can also load logs into DuckDB and use SQL:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "if Path('data/logs/clickstream.jsonl').exists():\n",
        "    con.execute(\"CREATE OR REPLACE TABLE logs AS SELECT * FROM read_json_auto('data/logs/clickstream.jsonl')\")\n",
        "    \n",
        "    result = con.execute(\"\"\"\n",
        "        SELECT event_type, COUNT(*) as count \n",
        "        FROM logs \n",
        "        GROUP BY event_type\n",
        "    \"\"\").df()\n",
        "    \n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using LanceDB for Semantic Search\n",
        "\n",
        "LanceDB is useful when you need to search by meaning rather than exact matches. Example use case: searching through log descriptions or PDF content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/panthbhavsar/Documents/theory/modeler-hackathon-starter/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log files not found.\n"
          ]
        }
      ],
      "source": [
        "import lancedb\n",
        "\n",
        "# Connect to LanceDB\n",
        "db = lancedb.connect('lance_db')\n",
        "\n",
        "# Example: Load log data into LanceDB\n",
        "if Path('data/logs/clickstream.jsonl').exists():\n",
        "    log_data = pd.read_json('data/logs/clickstream.jsonl', lines=True)\n",
        "    \n",
        "    # Create a table\n",
        "    table = db.create_table(\"logs\", data=log_data, mode=\"overwrite\")\n",
        "    \n",
        "    print(f\"Loaded {len(log_data)} rows into LanceDB\")\n",
        "    \n",
        "    # Query example: Filter logs\n",
        "    results = table.search().where(\"event_type = 'product_view'\").limit(5).to_pandas()\n",
        "    print(\"\\nSample product view events:\")\n",
        "    print(results)\n",
        "else:\n",
        "    print(\"Log files not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission Format\n",
        "\n",
        "Save your answers in CSV format:\n",
        "\n",
        "```csv\n",
        "question_id,answer_type,answer_value,confidence,explanation\n",
        "1,customer_id,12345,high,Top customer by revenue\n",
        "1,total_spent,50000,high,Sum of net_paid\n",
        "```\n",
        "\n",
        "Create submissions programmatically:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   question_id  answer_type  answer_value confidence              explanation\n",
            "0            1  customer_id         12345       high  Top customer by revenue\n",
            "1            1  total_spent         50000       high          Sum of net_paid\n"
          ]
        }
      ],
      "source": [
        "submission = pd.DataFrame([\n",
        "    {'question_id': 1, 'answer_type': 'customer_id', 'answer_value': 12345, 'confidence': 'high', 'explanation': 'Top customer by revenue'},\n",
        "    {'question_id': 1, 'answer_type': 'total_spent', 'answer_value': 50000, 'confidence': 'high', 'explanation': 'Sum of net_paid'},\n",
        "])\n",
        "\n",
        "print(submission)\n",
        "\n",
        "# To save:\n",
        "# submission.to_csv('my_submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Competition Structure\n",
        "\n",
        "**Training Round (12:30-2:00):** 25 questions with answers provided. Practice only, no submission required.\n",
        "\n",
        "**Test Round (2:00-6:00):** 30 questions without answers. Submit by 6:00 PM. Worth 70% of final score.\n",
        "\n",
        "**Holdout Round (6:00-7:30):** 20 secret questions. We run your system automatically. Worth 30% of final score.\n",
        "\n",
        "That's the basics. Check the README for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool Use Cases\n",
        "\n",
        "**DuckDB:** SQL queries on structured data (Parquet tables) and logs. Fast for aggregations, joins, filtering.\n",
        "\n",
        "**LanceDB:** Semantic search when you need to find things by meaning, not exact matches. Good for searching PDFs or finding similar log entries.\n",
        "\n",
        "**MotherDuck:** Cloud version of DuckDB. Useful for sharing data/queries with teammates or working with larger datasets.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
