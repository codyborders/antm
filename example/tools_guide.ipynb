{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Start Example (Optional)\n",
        "\n",
        "This notebook demonstrates basic data access patterns using DuckDB and pandas. For a deeper dive into building full analytics agents on MotherDuck (prompt design, MCP integration, security), see [MotherDuck’s analytics agent guide](https://motherduck.com/docs/key-tasks/ai-and-motherduck/building-analytics-agents/).\n",
        "\n",
        "## Contents\n",
        "- Tool installation\n",
        "- Loading Parquet files\n",
        "- SQL queries\n",
        "- Log file parsing\n",
        "- Submission format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Tools\n",
        "\n",
        "Run this once:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q duckdb pandas pyarrow lancedb\n",
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to DuckDB\n",
        "\n",
        "DuckDB lets you run SQL queries on Parquet files. It's fast and works well for analytics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "con = duckdb.connect('retail.duckdb')\n",
        "print(\"Connected to DuckDB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 1: Load Data into local DuckDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Parquet files into DuckDB so you can query them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all parquet files in our GCS bucket\n",
        "files = con.execute(\"SELECT file FROM glob('gs://antm-dataset/**/*.parquet')\").fetchall()\n",
        "\n",
        "# Create table for each file\n",
        "for file_path, in files:\n",
        "    table_name = Path(file_path).stem\n",
        "    con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM read_parquet('{file_path}')\")\n",
        "\n",
        "# Show tables\n",
        "print(f\"\\nCreated {len(files)} tables\")\n",
        "con.execute(\"SHOW TABLES\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 2: Connect to MotherDuck\n",
        "\n",
        "MotherDuck gives your local DuckDB cloud compute resources. It also lets you share data with others easily. \n",
        "\n",
        "1. Go to [app.motherduck.com](https://app.motherduck.com) and create an account.\n",
        "2. [create an access token](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-motherduck/authenticating-to-motherduck/#creating-an-access-token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"motherduck_token\"] = \"your_actual_token_here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Attach the 'atmn_hack' share with pre-loaded data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.environ.get(\"motherduck_token\") == \"your_actual_token_here\":\n",
        "    print(\"Using local DuckDB\")\n",
        "else:\n",
        "    print(\"Attaching MotherDuck 'antm_hack' share\")\n",
        "\n",
        "    con.execute(\"ATTACH 'md:_share/antm_hack/88329567-1b97-4593-9696-73fd2be9c63d'\")\n",
        "    con.execute(\"USE antm_hack\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run a Query\n",
        "\n",
        "Example: Find top customers by spending\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if customer_path.exists():\n",
        "    query = \"\"\"\n",
        "    SELECT \n",
        "        c_customer_sk,\n",
        "        c_first_name,\n",
        "        c_last_name\n",
        "    FROM customer\n",
        "    ORDER BY c_customer_sk\n",
        "    LIMIT 5\n",
        "    \"\"\"\n",
        "    \n",
        "    result = con.execute(query).df()\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Log Files\n",
        "\n",
        "Logs are in JSONL format (one JSON object per line). You can use pandas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if Path('dataset/logs/clickstream.jsonl').exists():\n",
        "    logs = pd.read_json('dataset/logs/clickstream.jsonl', lines=True)\n",
        "    print(f\"Loaded {len(logs)} events\")\n",
        "    print(logs.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Query Logs with DuckDB\n",
        "\n",
        "You can also load logs into DuckDB and use SQL:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if Path('dataset/logs/clickstream.jsonl').exists():\n",
        "    con.execute(\"CREATE OR REPLACE TABLE logs AS SELECT * FROM read_json_auto('dataset/logs/clickstream.jsonl')\")\n",
        "    \n",
        "    result = con.execute(\"\"\"\n",
        "        SELECT event_type, COUNT(*) as count \n",
        "        FROM logs \n",
        "        GROUP BY event_type\n",
        "    \"\"\").df()\n",
        "    \n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using LanceDB for Semantic Search\n",
        "\n",
        "LanceDB is useful when you need to search by meaning rather than exact matches. Example use case: searching through log descriptions or PDF content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lancedb\n",
        "\n",
        "# Connect to LanceDB\n",
        "db = lancedb.connect('lance_db')\n",
        "\n",
        "# Example: Load log data into LanceDB\n",
        "if Path('data/logs/clickstream.jsonl').exists():\n",
        "    log_data = pd.read_json('data/logs/clickstream.jsonl', lines=True)\n",
        "    \n",
        "    # Create a table\n",
        "    table = db.create_table(\"logs\", data=log_data, mode=\"overwrite\")\n",
        "    \n",
        "    print(f\"Loaded {len(log_data)} rows into LanceDB\")\n",
        "    \n",
        "    # Query example: Filter logs\n",
        "    results = table.search().where(\"event_type = 'product_view'\").limit(5).to_pandas()\n",
        "    print(\"\\nSample product view events:\")\n",
        "    print(results)\n",
        "else:\n",
        "    print(\"Log files not found.\")\n",
        "\n",
        "\n",
        "## Query LanceDB table or pandas DataFrame with DuckDB\n",
        "arrow_table = table.to_lance()\n",
        "con.query(\"SELECT * FROM arrow_table\")\n",
        "con.query(\"SELECT * FROM results\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission Format\n",
        "\n",
        "Save your answers in CSV format:\n",
        "\n",
        "```csv\n",
        "question_id,answer_type,answer_value,confidence,explanation\n",
        "1,customer_id,12345,high,Top customer by revenue\n",
        "1,total_spent,50000,high,Sum of net_paid\n",
        "```\n",
        "\n",
        "Create submissions programmatically:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission = pd.DataFrame([\n",
        "    {'question_id': 1, 'answer_type': 'customer_id', 'answer_value': 12345, 'confidence': 'high', 'explanation': 'Top customer by revenue'},\n",
        "    {'question_id': 1, 'answer_type': 'total_spent', 'answer_value': 50000, 'confidence': 'high', 'explanation': 'Sum of net_paid'},\n",
        "])\n",
        "\n",
        "print(submission)\n",
        "\n",
        "# To save:\n",
        "# submission.to_csv('my_submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Competition Structure\n",
        "\n",
        "**Training Round (12:30-2:00):** 25 questions with answers provided. Practice only, no submission required.\n",
        "\n",
        "**Test Round (2:00-6:00):** 30 questions without answers. Submit by 6:00 PM. Worth 70% of final score.\n",
        "\n",
        "**Holdout Round (6:00-7:30):** 20 secret questions. We run your system automatically. Worth 30% of final score.\n",
        "\n",
        "That's the basics. Check the README for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool Use Cases\n",
        "\n",
        "**DuckDB:** SQL queries on structured data (Parquet tables) and logs. Fast for aggregations, joins, filtering.\n",
        "\n",
        "**LanceDB:** Semantic search when you need to find things by meaning, not exact matches. Good for searching PDFs or finding similar log entries.\n",
        "\n",
        "**MotherDuck:** Cloud version of DuckDB. Useful for sharing data/queries with teammates or working with larger datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MCP Server Quickstart\n",
        "\n",
        "1. **Pick a language/runtime.** MCP servers only need stdin/stdout plus JSON-RPC. Python (`mcp`), TypeScript (`@modelcontextprotocol/server`), or Go all work.\n",
        "2. **Choose resources.** Decide what data you’ll expose (DuckDB tables, Parquet files, PDF search). Give each a stable URI so clients know how to reference them.\n",
        "3. **Implement tools.** Each MCP tool wraps an action—run SQL, summarize a log window, fetch a PDF section. Keep inputs/outputs typed and minimal so LLMs can call them safely.\n",
        "4. **Advertise capabilities.** In `initialize` return your tool/resource metadata so Cursor/Claude Desktop lists them automatically.\n",
        "5. **Run & register.** Start the server (e.g., `python mcp_server.py`) and add that command under `Cursor → Settings → MCP Servers`.\n",
        "\n",
        "Minimal Python scaffold:\n",
        "\n",
        "```python\n",
        "from mcp.server.fastmcp import FastMCPServer\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect('retail.duckdb')\n",
        "server = FastMCPServer()\n",
        "\n",
        "@server.tool()\n",
        "def describe_customer(limit: int = 5) -> list[dict[str, str]]:\n",
        "    \"\"\"Return sample customer rows from DuckDB.\"\"\"\n",
        "    rows = con.execute(\n",
        "        \"SELECT c_customer_sk, c_first_name, c_last_name FROM customer LIMIT ?\",\n",
        "        [limit],\n",
        "    ).fetchall()\n",
        "    return [dict(row) for row in rows]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    server.run()\n",
        "```\n",
        "\n",
        "Register `python mcp_server.py` as a custom MCP server and the `describe_customer` tool becomes available directly in your prompts.\n",
        "\n",
        "> **Shortcut:** Don’t want to build your own? MotherDuck ships an OSS MCP server that connects to both DuckDB and MotherDuck backends, complete with SaaS/read-only modes and Claude/Cursor examples. Install it via `uvx mcp-server-motherduck …` using the instructions in their repo: https://github.com/motherduckdb/mcp-server-motherduck.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
